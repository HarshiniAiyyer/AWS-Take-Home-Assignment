{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e1089fc-9290-48d9-89fd-3411deae6a92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\n",
      "Collecting psycopg2-binary\n",
      "  Using cached psycopg2_binary-2.9.10-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Requirement already satisfied: boto3 in /databricks/python3/lib/python3.9/site-packages (1.21.32)\n",
      "Requirement already satisfied: botocore<1.25.0,>=1.24.32 in /databricks/python3/lib/python3.9/site-packages (from boto3) (1.24.32)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /databricks/python3/lib/python3.9/site-packages (from boto3) (0.5.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /databricks/python3/lib/python3.9/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /databricks/python3/lib/python3.9/site-packages (from botocore<1.25.0,>=1.24.32->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /databricks/python3/lib/python3.9/site-packages (from botocore<1.25.0,>=1.24.32->boto3) (1.26.9)\n",
      "Requirement already satisfied: six>=1.5 in /databricks/python3/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.32->boto3) (1.16.0)\n",
      "Installing collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.9.10\n",
      "Python interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install psycopg2-binary boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c436a88-5c07-426a-a97f-d2b85b8f46ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PostgreSQL connection successful: PostgreSQL 17.4 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 12.4.0, 64-bit\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: Test PostgreSQL connection\n",
    "try:\n",
    "    conn = psycopg2.connect(**PG_CONFIG)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT version();\")\n",
    "    version = cur.fetchone()\n",
    "    print(f\"âœ… PostgreSQL connection successful: {version[0]}\")\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(f\"âŒ PostgreSQL connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07e90107-1a22-495c-b4d9-f4584a1f67e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Database 'bankdata' already exists\n"
     ]
    }
   ],
   "source": [
    "# CELL 4: Create the bankdata database (if needed)\n",
    "try:\n",
    "    conn = psycopg2.connect(**PG_CONFIG)\n",
    "    conn.autocommit = True\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    cur.execute(\"CREATE DATABASE bankdata;\")\n",
    "    print(\"âœ… Database 'bankdata' created successfully\")\n",
    "    \n",
    "    cur.close()\n",
    "    conn.close()\n",
    "except psycopg2.errors.DuplicateDatabase:\n",
    "    print(\"âš ï¸ Database 'bankdata' already exists\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error creating database: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c821fdc-fc43-4fe6-8a2a-f8cb2562e640",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tables created successfully\n"
     ]
    }
   ],
   "source": [
    "# CELL 5: Connect to your bankdata database and create tables\n",
    "PG_CONFIG['database'] = 'bankdata'  # Switch to your target database\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(**PG_CONFIG)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    # Create your tracking table\n",
    "    cur.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS processed_chunks (\n",
    "            chunk_id TEXT PRIMARY KEY,\n",
    "            processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "        );\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    print(\"âœ… Tables created successfully\")\n",
    "    \n",
    "    cur.close()\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error creating tables: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c9228cf-f52a-4a73-afa2-34f61c2de112",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… S3 configuration complete\n"
     ]
    }
   ],
   "source": [
    "# CELL 6: Set up S3 configuration (only if you need S3 access)\n",
    "if 'AWS_ACCESS_KEY_ID' in os.environ:\n",
    "    # Configure Spark for S3 access\n",
    "    sc._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", os.environ['AWS_ACCESS_KEY_ID'])\n",
    "    sc._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", os.environ['AWS_SECRET_ACCESS_KEY'])\n",
    "    sc._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"s3.amazonaws.com\")\n",
    "    \n",
    "    # Set up boto3 S3 client\n",
    "    session = boto3.Session(\n",
    "        aws_access_key_id=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "        aws_secret_access_key=os.environ[\"AWS_SECRET_ACCESS_KEY\"]\n",
    "    )\n",
    "    s3 = session.client('s3', config=Config(signature_version='s3v4'))\n",
    "    print(\"âœ… S3 configuration complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ea05848-9b0e-4a78-bc8f-f46e05e360d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All functions defined\n"
     ]
    }
   ],
   "source": [
    "# CELL 7: Your utility functions\n",
    "def get_processed_chunks():\n",
    "    conn = psycopg2.connect(**PG_CONFIG)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT chunk_id FROM processed_chunks\")\n",
    "    chunks = {row[0] for row in cur.fetchall()}\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return chunks\n",
    "\n",
    "def list_s3_chunk_folders():\n",
    "    response = s3.list_objects_v2(Bucket='banktransactionskrnl1', Prefix='chunks/', Delimiter='/')\n",
    "    folders = [prefix['Prefix'].split('/')[-2] for prefix in response.get('CommonPrefixes', [])]\n",
    "    return folders\n",
    "\n",
    "def get_new_chunks():\n",
    "    processed = get_processed_chunks()\n",
    "    available = list_s3_chunk_folders()\n",
    "    new_chunks = [chunk for chunk in available if chunk not in processed]\n",
    "    return new_chunks\n",
    "\n",
    "print(\"âœ… All functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3543026b-db1b-408e-9b38-e1bbf52c9a3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŸ¢ New chunks found:\n",
      " - chunk_0_20250605035607\n",
      " - chunk_10_20250605040201\n",
      " - chunk_11_20250605040236\n",
      " - chunk_12_20250605040310\n",
      " - chunk_13_20250605040344\n",
      " - chunk_14_20250605040419\n",
      " - chunk_15_20250605040453\n",
      " - chunk_16_20250605040528\n",
      " - chunk_17_20250605040602\n",
      " - chunk_18_20250605040636\n",
      " - chunk_19_20250605040710\n",
      " - chunk_1_20250605035643\n",
      " - chunk_20_20250605040744\n",
      " - chunk_21_20250605040819\n",
      " - chunk_22_20250605040853\n",
      " - chunk_23_20250605040927\n",
      " - chunk_24_20250605041001\n",
      " - chunk_25_20250605041035\n",
      " - chunk_26_20250605041109\n",
      " - chunk_27_20250605041144\n",
      " - chunk_28_20250605041219\n",
      " - chunk_29_20250605041253\n",
      " - chunk_2_20250605035718\n",
      " - chunk_30_20250605041328\n",
      " - chunk_31_20250605041401\n",
      " - chunk_32_20250605041435\n",
      " - chunk_33_20250605041510\n",
      " - chunk_34_20250605041544\n",
      " - chunk_35_20250605041618\n",
      " - chunk_36_20250605041653\n",
      " - chunk_37_20250605041727\n",
      " - chunk_38_20250605041802\n",
      " - chunk_39_20250605041836\n",
      " - chunk_3_20250605035754\n",
      " - chunk_40_20250605041910\n",
      " - chunk_41_20250605041944\n",
      " - chunk_42_20250605042018\n",
      " - chunk_43_20250605042053\n",
      " - chunk_44_20250605042127\n",
      " - chunk_45_20250605042202\n",
      " - chunk_46_20250605042237\n",
      " - chunk_47_20250605042311\n",
      " - chunk_48_20250605042344\n",
      " - chunk_49_20250605042418\n",
      " - chunk_4_20250605035829\n",
      " - chunk_50_20250605042453\n",
      " - chunk_51_20250605042527\n",
      " - chunk_52_20250605042601\n",
      " - chunk_53_20250605042635\n",
      " - chunk_54_20250605042709\n",
      " - chunk_55_20250605042744\n",
      " - chunk_56_20250605042817\n",
      " - chunk_57_20250605042851\n",
      " - chunk_58_20250605042925\n",
      " - chunk_59_20250605043002\n",
      " - chunk_5_20250605035904\n",
      " - chunk_6_20250605035939\n",
      " - chunk_7_20250605040015\n",
      " - chunk_8_20250605040051\n",
      " - chunk_9_20250605040127\n"
     ]
    }
   ],
   "source": [
    "# CELL 8: Test your pipeline\n",
    "try:\n",
    "    new_chunks = get_new_chunks()\n",
    "    if new_chunks:\n",
    "        print(\"ğŸŸ¢ New chunks found:\")\n",
    "        for chunk in new_chunks:\n",
    "            print(f\" - {chunk}\")\n",
    "    else:\n",
    "        print(\"ğŸŸ¡ No new chunks found to process\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error checking chunks: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b110c48-4c3b-4e77-a8a4-1faf47c81935",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Detecting Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9297d02-7744-4d82-816d-4776f0e2689e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, avg, lit, current_timestamp, percent_rank\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.window import Window\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "import psycopg2\n",
    "\n",
    "def mark_chunk_processed(chunk_id):\n",
    "    conn = psycopg2.connect(**PG_CONFIG)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"INSERT INTO processed_chunks (chunk_id, processed_at) VALUES (%s, %s) ON CONFLICT DO NOTHING\", \n",
    "                (chunk_id, datetime.now()))\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "def process_chunk(chunk_id):\n",
    "    s3_path = f\"s3a://banktransactionskrnl1/chunks/{chunk_id}/\"\n",
    "    print(f\"ğŸ“¦ Processing chunk: {chunk_id}\")\n",
    "    \n",
    "    # Load chunk\n",
    "    df_chunk = spark.read.option(\"header\", True).csv(s3_path)\n",
    "    df_chunk = df_chunk.withColumn(\"amount\", col(\"amount\").cast(\"float\"))\n",
    "    \n",
    "    ### -------- Pattern 1: UPGRADE -------- ###\n",
    "    trans_df = df_chunk.groupBy(\"merchant\", \"customer\").agg(count(\"*\").alias(\"txn_count\"))\n",
    "    \n",
    "    enriched_df = trans_df.join(cdf, on=[\"merchant\", \"customer\"], how=\"left\") \\\n",
    "                          .withColumn(\"Weight\", col(\"Weight\").cast(\"float\")) \\\n",
    "                          .withColumn(\"txn_count\", col(\"txn_count\").cast(\"int\"))\n",
    "    \n",
    "    merchant_total_txns = df_chunk.groupBy(\"merchant\").agg(count(\"*\").alias(\"total_txns\")) \\\n",
    "                                  .filter(col(\"total_txns\") > 50000)\n",
    "\n",
    "    percentile_joined = enriched_df.join(merchant_total_txns, on=\"merchant\", how=\"inner\")\n",
    "\n",
    "    window_spec = Window.partitionBy(\"merchant\").orderBy(col(\"txn_count\").desc())\n",
    "    percent_ranked = percentile_joined.withColumn(\"rank\", percent_rank().over(window_spec))\n",
    "\n",
    "    pattern1_output = percent_ranked.filter((col(\"rank\") <= 0.01) & (col(\"Weight\") <= 0.01)) \\\n",
    "        .withColumn(\"YStartTime\", lit(datetime.now().isoformat())) \\\n",
    "        .withColumn(\"detectionTime\", current_timestamp()) \\\n",
    "        .withColumn(\"patternId\", lit(\"PatId1\")) \\\n",
    "        .withColumn(\"ActionType\", lit(\"UPGRADE\")) \\\n",
    "        .withColumnRenamed(\"customer\", \"customerName\") \\\n",
    "        .withColumnRenamed(\"merchant\", \"MerchantId\") \\\n",
    "        .select(\"YStartTime\", \"detectionTime\", \"patternId\", \"ActionType\", \"customerName\", \"MerchantId\")\n",
    "\n",
    "    if pattern1_output.count() > 0:\n",
    "        print(f\"âœ… {pattern1_output.count()} UPGRADE detections found in chunk {chunk_id}\")\n",
    "        for i, batch in enumerate(pattern1_output.randomSplit([1.0] * ((pattern1_output.count() // 50) + 1))):\n",
    "            if batch.count() > 0:\n",
    "                output_path = f\"s3a://banktransactionskrnl1/detections/test_detection_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}.csv\"\n",
    "                batch.write.mode(\"overwrite\").option(\"header\", True).csv(output_path)\n",
    "                print(f\"ğŸ’¾ Saved UPGRADE batch {i+1} to {output_path}\")\n",
    "    else:\n",
    "        print(f\"âšª No Pattern 1 detections for chunk {chunk_id}\")\n",
    "    \n",
    "    ### -------- Pattern 2: CHILD -------- ###\n",
    "    grouped_df = df_chunk.groupBy(\"customer\", \"merchant\") \\\n",
    "                         .agg(count(\"*\").alias(\"txn_count\"), avg(\"amount\").alias(\"avg_amt\"))\n",
    "\n",
    "    pattern2_output = grouped_df.filter((col(\"avg_amt\") < 23) & (col(\"txn_count\") >= 80)) \\\n",
    "        .withColumn(\"YStartTime\", lit(datetime.now().isoformat())) \\\n",
    "        .withColumn(\"detectionTime\", current_timestamp()) \\\n",
    "        .withColumn(\"patternId\", lit(\"PatId2\")) \\\n",
    "        .withColumn(\"ActionType\", lit(\"CHILD\")) \\\n",
    "        .withColumnRenamed(\"customer\", \"customerName\") \\\n",
    "        .withColumnRenamed(\"merchant\", \"MerchantId\") \\\n",
    "        .select(\"YStartTime\", \"detectionTime\", \"patternId\", \"ActionType\", \"customerName\", \"MerchantId\")\n",
    "\n",
    "    if pattern2_output.count() > 0:\n",
    "        print(f\"âœ… {pattern2_output.count()} CHILD detections found in chunk {chunk_id}\")\n",
    "        for i, batch in enumerate(pattern2_output.randomSplit([1.0] * ((pattern2_output.count() // 50) + 1))):\n",
    "            if batch.count() > 0:\n",
    "                output_path = f\"s3a://banktransactionskrnl1/detections/test_detection_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}.csv\"\n",
    "                batch.write.mode(\"overwrite\").option(\"header\", True).csv(output_path)\n",
    "                print(f\"ğŸ’¾ Saved CHILD batch {i+1} to {output_path}\")\n",
    "    else:\n",
    "        print(f\"âšª No Pattern 2 detections for chunk {chunk_id}\")\n",
    "    \n",
    "\n",
    "    ### -------- Pattern 3: DEI-NEEDED -------- ###  \n",
    "\n",
    "    cleans_df = df_chunk.withColumn(\"gender_clean\", regexp_replace(col(\"gender\"), \"'\", \"\"))\n",
    "\n",
    "    gender_df = cleans_df.select(\"merchant\", \"gender_clean\") \\\n",
    "                        .filter(col(\"gender_clean\").isin(\"F\", \"M\"))\n",
    "\n",
    "    # ğŸ› ï¸ Use pivot with fixed values, fill missing with 0\n",
    "    gender_counts = gender_df.groupBy(\"merchant\") \\\n",
    "        .pivot(\"gender_clean\", [\"F\", \"M\"]) \\\n",
    "        .count() \\\n",
    "        .na.fill(0)\n",
    "\n",
    "    # Now F and M columns are guaranteed to exist\n",
    "    pattern3_matches = gender_counts.filter((col(\"F\") > 100) & (col(\"F\") < col(\"M\")))\n",
    "\n",
    "    pattern3_output = pattern3_matches.withColumn(\"YStartTime\", lit(datetime.now().isoformat())) \\\n",
    "        .withColumn(\"detectionTime\", current_timestamp()) \\\n",
    "        .withColumn(\"patternId\", lit(\"PatId3\")) \\\n",
    "        .withColumn(\"ActionType\", lit(\"DEI-NEEDED\")) \\\n",
    "        .withColumnRenamed(\"merchant\", \"MerchantId\") \\\n",
    "        .withColumn(\"customerName\", lit(\"\")) \\\n",
    "        .select(\"YStartTime\", \"detectionTime\", \"patternId\", \"ActionType\", \"customerName\", \"MerchantId\")\n",
    "\n",
    "    if pattern3_output.count() > 0:\n",
    "        print(f\"âœ… {pattern3_output.count()} DEI-NEEDED detections found in chunk {chunk_id}\")\n",
    "        for i, batch in enumerate(pattern3_output.randomSplit([1.0] * ((pattern3_output.count() // 50) + 1))):\n",
    "            if batch.count() > 0:\n",
    "                output_path = f\"s3a://banktransactionskrnl1/detections/test_detection_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}.csv\"\n",
    "                batch.write.mode(\"overwrite\").option(\"header\", True).csv(output_path)\n",
    "                print(f\"ğŸ’¾ Saved DEI-NEEDED batch {i+1} to {output_path}\")\n",
    "    else:\n",
    "        print(f\"âšª No Pattern 3 detections for chunk {chunk_id}\")\n",
    "    \n",
    "    # âœ… Mark chunk as processed\n",
    "    mark_chunk_processed(chunk_id)\n",
    "    print(f\"âœ… Marked chunk {chunk_id} as processed\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8adae2c-6c60-400e-a841-ccb577be86c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cdf = spark.read.option(\"header\", True).csv(\"dbfs:/FileStore/tables/CustomerImportance.csv\")\n",
    "cdf = cdf.withColumnRenamed(\"Source\", \"customer\") \\\n",
    "                                               .withColumnRenamed(\"Target\", \"merchant\") \\\n",
    "                                               .withColumnRenamed(\"typeTrans\", \"category\") \\\n",
    "                                               .withColumn(\"Weight\", col(\"Weight\").cast(\"float\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "e8e46e7c-b006-4d40-bc63-1d7468388d9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grouped_df = df_chunk.groupBy(\"customer\", \"merchant\") \\\n",
    "                         .agg(count(\"*\").alias(\"txn_count\"), avg(\"amount\").alias(\"avg_amt\"))\n",
    "grouped_df.orderBy(\"txn_count\", ascending=False).show()\n",
    "grouped_df.filter(col(\"txn_count\") >= 80).orderBy(\"avg_amt\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d85c45c-1e08-4c5e-b159-6ea9429291a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, regexp_replace\n",
    "\n",
    "# ğŸ§¼ Step 1: Clean gender values by removing apostrophes\n",
    "cleans_df = df_chunk.withColumn(\"gender_clean\", regexp_replace(col(\"gender\"), \"'\", \"\"))\n",
    "\n",
    "# ğŸ” Step 2: Filter only valid gender values (\"F\", \"M\")\n",
    "gender_df = cleans_df.select(\"merchant\", \"gender_clean\") \\\n",
    "                     .filter(col(\"gender_clean\").isin(\"F\", \"M\"))\n",
    "\n",
    "# âœ… Optional: View unique cleaned gender values to verify\n",
    "gender_df.select(\"gender_clean\").distinct().show()\n",
    "\n",
    "# ğŸ“Š Step 3: Pivot table to count F and M by merchant\n",
    "gender_counts = gender_df.groupBy(\"merchant\") \\\n",
    "    .pivot(\"gender_clean\", [\"F\", \"M\"]) \\\n",
    "    .count() \\\n",
    "    .na.fill(0)\n",
    "\n",
    "# ğŸ‘€ Step 4: Display top merchants with most female customers\n",
    "gender_counts.orderBy(\"F\", ascending=False).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec0811e6-839f-43cb-87a3-9f573d591008",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_chunk.select(\"gender\").distinct().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82216dba-1a3b-4fed-94bc-b009731e303f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Testing a sample chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d38b1c0-6118-48b2-9d00-c0d7873c3df0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "process_chunk(\"chunk_0_20250604172038/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28ced991-a09f-4d0e-84df-0096dd3e461c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Starting Mechanism Y polling (5-minute session)...\n",
      "ğŸ“¦ Processing chunk: chunk_0_20250605035607\n",
      "âšª No Pattern 1 detections for chunk chunk_0_20250605035607\n",
      "âšª No Pattern 2 detections for chunk chunk_0_20250605035607\n",
      "âšª No Pattern 3 detections for chunk chunk_0_20250605035607\n",
      "âœ… Marked chunk chunk_0_20250605035607 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_10_20250605040201\n",
      "âšª No Pattern 1 detections for chunk chunk_10_20250605040201\n",
      "âšª No Pattern 2 detections for chunk chunk_10_20250605040201\n",
      "âšª No Pattern 3 detections for chunk chunk_10_20250605040201\n",
      "âœ… Marked chunk chunk_10_20250605040201 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_11_20250605040236\n",
      "âšª No Pattern 1 detections for chunk chunk_11_20250605040236\n",
      "âšª No Pattern 2 detections for chunk chunk_11_20250605040236\n",
      "âšª No Pattern 3 detections for chunk chunk_11_20250605040236\n",
      "âœ… Marked chunk chunk_11_20250605040236 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_12_20250605040310\n",
      "âšª No Pattern 1 detections for chunk chunk_12_20250605040310\n",
      "âšª No Pattern 2 detections for chunk chunk_12_20250605040310\n",
      "âšª No Pattern 3 detections for chunk chunk_12_20250605040310\n",
      "âœ… Marked chunk chunk_12_20250605040310 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_13_20250605040344\n",
      "âšª No Pattern 1 detections for chunk chunk_13_20250605040344\n",
      "âšª No Pattern 2 detections for chunk chunk_13_20250605040344\n",
      "âšª No Pattern 3 detections for chunk chunk_13_20250605040344\n",
      "âœ… Marked chunk chunk_13_20250605040344 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_14_20250605040419\n",
      "âšª No Pattern 1 detections for chunk chunk_14_20250605040419\n",
      "âšª No Pattern 2 detections for chunk chunk_14_20250605040419\n",
      "âšª No Pattern 3 detections for chunk chunk_14_20250605040419\n",
      "âœ… Marked chunk chunk_14_20250605040419 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_15_20250605040453\n",
      "âšª No Pattern 1 detections for chunk chunk_15_20250605040453\n",
      "âšª No Pattern 2 detections for chunk chunk_15_20250605040453\n",
      "âšª No Pattern 3 detections for chunk chunk_15_20250605040453\n",
      "âœ… Marked chunk chunk_15_20250605040453 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_16_20250605040528\n",
      "âšª No Pattern 1 detections for chunk chunk_16_20250605040528\n",
      "âšª No Pattern 2 detections for chunk chunk_16_20250605040528\n",
      "âšª No Pattern 3 detections for chunk chunk_16_20250605040528\n",
      "âœ… Marked chunk chunk_16_20250605040528 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_17_20250605040602\n",
      "âšª No Pattern 1 detections for chunk chunk_17_20250605040602\n",
      "âšª No Pattern 2 detections for chunk chunk_17_20250605040602\n",
      "âšª No Pattern 3 detections for chunk chunk_17_20250605040602\n",
      "âœ… Marked chunk chunk_17_20250605040602 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_18_20250605040636\n",
      "âšª No Pattern 1 detections for chunk chunk_18_20250605040636\n",
      "âšª No Pattern 2 detections for chunk chunk_18_20250605040636\n",
      "âšª No Pattern 3 detections for chunk chunk_18_20250605040636\n",
      "âœ… Marked chunk chunk_18_20250605040636 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_19_20250605040710\n",
      "âšª No Pattern 1 detections for chunk chunk_19_20250605040710\n",
      "âšª No Pattern 2 detections for chunk chunk_19_20250605040710\n",
      "âšª No Pattern 3 detections for chunk chunk_19_20250605040710\n",
      "âœ… Marked chunk chunk_19_20250605040710 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_1_20250605035643\n",
      "âšª No Pattern 1 detections for chunk chunk_1_20250605035643\n",
      "âšª No Pattern 2 detections for chunk chunk_1_20250605035643\n",
      "âšª No Pattern 3 detections for chunk chunk_1_20250605035643\n",
      "âœ… Marked chunk chunk_1_20250605035643 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_20_20250605040744\n",
      "âšª No Pattern 1 detections for chunk chunk_20_20250605040744\n",
      "âšª No Pattern 2 detections for chunk chunk_20_20250605040744\n",
      "âšª No Pattern 3 detections for chunk chunk_20_20250605040744\n",
      "âœ… Marked chunk chunk_20_20250605040744 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_21_20250605040819\n",
      "âšª No Pattern 1 detections for chunk chunk_21_20250605040819\n",
      "âšª No Pattern 2 detections for chunk chunk_21_20250605040819\n",
      "âšª No Pattern 3 detections for chunk chunk_21_20250605040819\n",
      "âœ… Marked chunk chunk_21_20250605040819 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_22_20250605040853\n",
      "âšª No Pattern 1 detections for chunk chunk_22_20250605040853\n",
      "âšª No Pattern 2 detections for chunk chunk_22_20250605040853\n",
      "âœ… 1 DEI-NEEDED detections found in chunk chunk_22_20250605040853\n",
      "ğŸ’¾ Saved DEI-NEEDED batch 1 to s3a://banktransactionskrnl1/detections/test_detection_20250605_044725_01a77242.csv\n",
      "âœ… Marked chunk chunk_22_20250605040853 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_23_20250605040927\n",
      "âšª No Pattern 1 detections for chunk chunk_23_20250605040927\n",
      "âšª No Pattern 2 detections for chunk chunk_23_20250605040927\n",
      "âšª No Pattern 3 detections for chunk chunk_23_20250605040927\n",
      "âœ… Marked chunk chunk_23_20250605040927 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_24_20250605041001\n",
      "âšª No Pattern 1 detections for chunk chunk_24_20250605041001\n",
      "âšª No Pattern 2 detections for chunk chunk_24_20250605041001\n",
      "âšª No Pattern 3 detections for chunk chunk_24_20250605041001\n",
      "âœ… Marked chunk chunk_24_20250605041001 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_25_20250605041035\n",
      "âšª No Pattern 1 detections for chunk chunk_25_20250605041035\n",
      "âšª No Pattern 2 detections for chunk chunk_25_20250605041035\n",
      "âšª No Pattern 3 detections for chunk chunk_25_20250605041035\n",
      "âœ… Marked chunk chunk_25_20250605041035 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_26_20250605041109\n",
      "âšª No Pattern 1 detections for chunk chunk_26_20250605041109\n",
      "âšª No Pattern 2 detections for chunk chunk_26_20250605041109\n",
      "âšª No Pattern 3 detections for chunk chunk_26_20250605041109\n",
      "âœ… Marked chunk chunk_26_20250605041109 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_27_20250605041144\n",
      "âšª No Pattern 1 detections for chunk chunk_27_20250605041144\n",
      "âšª No Pattern 2 detections for chunk chunk_27_20250605041144\n",
      "âšª No Pattern 3 detections for chunk chunk_27_20250605041144\n",
      "âœ… Marked chunk chunk_27_20250605041144 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_28_20250605041219\n",
      "âšª No Pattern 1 detections for chunk chunk_28_20250605041219\n",
      "âšª No Pattern 2 detections for chunk chunk_28_20250605041219\n",
      "âšª No Pattern 3 detections for chunk chunk_28_20250605041219\n",
      "âœ… Marked chunk chunk_28_20250605041219 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_29_20250605041253\n",
      "âšª No Pattern 1 detections for chunk chunk_29_20250605041253\n",
      "âšª No Pattern 2 detections for chunk chunk_29_20250605041253\n",
      "âšª No Pattern 3 detections for chunk chunk_29_20250605041253\n",
      "âœ… Marked chunk chunk_29_20250605041253 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_2_20250605035718\n",
      "âšª No Pattern 1 detections for chunk chunk_2_20250605035718\n",
      "âšª No Pattern 2 detections for chunk chunk_2_20250605035718\n",
      "âšª No Pattern 3 detections for chunk chunk_2_20250605035718\n",
      "âœ… Marked chunk chunk_2_20250605035718 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_30_20250605041328\n",
      "âšª No Pattern 1 detections for chunk chunk_30_20250605041328\n",
      "âšª No Pattern 2 detections for chunk chunk_30_20250605041328\n",
      "âšª No Pattern 3 detections for chunk chunk_30_20250605041328\n",
      "âœ… Marked chunk chunk_30_20250605041328 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_31_20250605041401\n",
      "âšª No Pattern 1 detections for chunk chunk_31_20250605041401\n",
      "âšª No Pattern 2 detections for chunk chunk_31_20250605041401\n",
      "âšª No Pattern 3 detections for chunk chunk_31_20250605041401\n",
      "âœ… Marked chunk chunk_31_20250605041401 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_32_20250605041435\n",
      "âšª No Pattern 1 detections for chunk chunk_32_20250605041435\n",
      "âšª No Pattern 2 detections for chunk chunk_32_20250605041435\n",
      "âšª No Pattern 3 detections for chunk chunk_32_20250605041435\n",
      "âœ… Marked chunk chunk_32_20250605041435 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_33_20250605041510\n",
      "âšª No Pattern 1 detections for chunk chunk_33_20250605041510\n",
      "âšª No Pattern 2 detections for chunk chunk_33_20250605041510\n",
      "âšª No Pattern 3 detections for chunk chunk_33_20250605041510\n",
      "âœ… Marked chunk chunk_33_20250605041510 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_34_20250605041544\n",
      "âšª No Pattern 1 detections for chunk chunk_34_20250605041544\n",
      "âšª No Pattern 2 detections for chunk chunk_34_20250605041544\n",
      "âšª No Pattern 3 detections for chunk chunk_34_20250605041544\n",
      "âœ… Marked chunk chunk_34_20250605041544 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_35_20250605041618\n",
      "âšª No Pattern 1 detections for chunk chunk_35_20250605041618\n",
      "âšª No Pattern 2 detections for chunk chunk_35_20250605041618\n",
      "âšª No Pattern 3 detections for chunk chunk_35_20250605041618\n",
      "âœ… Marked chunk chunk_35_20250605041618 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_36_20250605041653\n",
      "âšª No Pattern 1 detections for chunk chunk_36_20250605041653\n",
      "âšª No Pattern 2 detections for chunk chunk_36_20250605041653\n",
      "âšª No Pattern 3 detections for chunk chunk_36_20250605041653\n",
      "âœ… Marked chunk chunk_36_20250605041653 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_37_20250605041727\n",
      "âšª No Pattern 1 detections for chunk chunk_37_20250605041727\n",
      "âšª No Pattern 2 detections for chunk chunk_37_20250605041727\n",
      "âšª No Pattern 3 detections for chunk chunk_37_20250605041727\n",
      "âœ… Marked chunk chunk_37_20250605041727 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_38_20250605041802\n",
      "âšª No Pattern 1 detections for chunk chunk_38_20250605041802\n",
      "âšª No Pattern 2 detections for chunk chunk_38_20250605041802\n",
      "âšª No Pattern 3 detections for chunk chunk_38_20250605041802\n",
      "âœ… Marked chunk chunk_38_20250605041802 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_39_20250605041836\n",
      "âšª No Pattern 1 detections for chunk chunk_39_20250605041836\n",
      "âšª No Pattern 2 detections for chunk chunk_39_20250605041836\n",
      "âšª No Pattern 3 detections for chunk chunk_39_20250605041836\n",
      "âœ… Marked chunk chunk_39_20250605041836 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_3_20250605035754\n",
      "âšª No Pattern 1 detections for chunk chunk_3_20250605035754\n",
      "âšª No Pattern 2 detections for chunk chunk_3_20250605035754\n",
      "âšª No Pattern 3 detections for chunk chunk_3_20250605035754\n",
      "âœ… Marked chunk chunk_3_20250605035754 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_40_20250605041910\n",
      "âšª No Pattern 1 detections for chunk chunk_40_20250605041910\n",
      "âšª No Pattern 2 detections for chunk chunk_40_20250605041910\n",
      "âšª No Pattern 3 detections for chunk chunk_40_20250605041910\n",
      "âœ… Marked chunk chunk_40_20250605041910 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_41_20250605041944\n",
      "âšª No Pattern 1 detections for chunk chunk_41_20250605041944\n",
      "âšª No Pattern 2 detections for chunk chunk_41_20250605041944\n",
      "âšª No Pattern 3 detections for chunk chunk_41_20250605041944\n",
      "âœ… Marked chunk chunk_41_20250605041944 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_42_20250605042018\n",
      "âšª No Pattern 1 detections for chunk chunk_42_20250605042018\n",
      "âšª No Pattern 2 detections for chunk chunk_42_20250605042018\n",
      "âšª No Pattern 3 detections for chunk chunk_42_20250605042018\n",
      "âœ… Marked chunk chunk_42_20250605042018 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_43_20250605042053\n",
      "âšª No Pattern 1 detections for chunk chunk_43_20250605042053\n",
      "âšª No Pattern 2 detections for chunk chunk_43_20250605042053\n",
      "âšª No Pattern 3 detections for chunk chunk_43_20250605042053\n",
      "âœ… Marked chunk chunk_43_20250605042053 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_44_20250605042127\n",
      "âšª No Pattern 1 detections for chunk chunk_44_20250605042127\n",
      "âšª No Pattern 2 detections for chunk chunk_44_20250605042127\n",
      "âšª No Pattern 3 detections for chunk chunk_44_20250605042127\n",
      "âœ… Marked chunk chunk_44_20250605042127 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_45_20250605042202\n",
      "âšª No Pattern 1 detections for chunk chunk_45_20250605042202\n",
      "âšª No Pattern 2 detections for chunk chunk_45_20250605042202\n",
      "âšª No Pattern 3 detections for chunk chunk_45_20250605042202\n",
      "âœ… Marked chunk chunk_45_20250605042202 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_46_20250605042237\n",
      "âšª No Pattern 1 detections for chunk chunk_46_20250605042237\n",
      "âšª No Pattern 2 detections for chunk chunk_46_20250605042237\n",
      "âšª No Pattern 3 detections for chunk chunk_46_20250605042237\n",
      "âœ… Marked chunk chunk_46_20250605042237 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_47_20250605042311\n",
      "âšª No Pattern 1 detections for chunk chunk_47_20250605042311\n",
      "âšª No Pattern 2 detections for chunk chunk_47_20250605042311\n",
      "âšª No Pattern 3 detections for chunk chunk_47_20250605042311\n",
      "âœ… Marked chunk chunk_47_20250605042311 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_48_20250605042344\n",
      "âšª No Pattern 1 detections for chunk chunk_48_20250605042344\n",
      "âšª No Pattern 2 detections for chunk chunk_48_20250605042344\n",
      "âšª No Pattern 3 detections for chunk chunk_48_20250605042344\n",
      "âœ… Marked chunk chunk_48_20250605042344 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_49_20250605042418\n",
      "âšª No Pattern 1 detections for chunk chunk_49_20250605042418\n",
      "âšª No Pattern 2 detections for chunk chunk_49_20250605042418\n",
      "âšª No Pattern 3 detections for chunk chunk_49_20250605042418\n",
      "âœ… Marked chunk chunk_49_20250605042418 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_4_20250605035829\n",
      "âšª No Pattern 1 detections for chunk chunk_4_20250605035829\n",
      "âšª No Pattern 2 detections for chunk chunk_4_20250605035829\n",
      "âšª No Pattern 3 detections for chunk chunk_4_20250605035829\n",
      "âœ… Marked chunk chunk_4_20250605035829 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_50_20250605042453\n",
      "âšª No Pattern 1 detections for chunk chunk_50_20250605042453\n",
      "âšª No Pattern 2 detections for chunk chunk_50_20250605042453\n",
      "âšª No Pattern 3 detections for chunk chunk_50_20250605042453\n",
      "âœ… Marked chunk chunk_50_20250605042453 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_51_20250605042527\n",
      "âšª No Pattern 1 detections for chunk chunk_51_20250605042527\n",
      "âšª No Pattern 2 detections for chunk chunk_51_20250605042527\n",
      "âšª No Pattern 3 detections for chunk chunk_51_20250605042527\n",
      "âœ… Marked chunk chunk_51_20250605042527 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_52_20250605042601\n",
      "âšª No Pattern 1 detections for chunk chunk_52_20250605042601\n",
      "âšª No Pattern 2 detections for chunk chunk_52_20250605042601\n",
      "âšª No Pattern 3 detections for chunk chunk_52_20250605042601\n",
      "âœ… Marked chunk chunk_52_20250605042601 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_53_20250605042635\n",
      "âšª No Pattern 1 detections for chunk chunk_53_20250605042635\n",
      "âšª No Pattern 2 detections for chunk chunk_53_20250605042635\n",
      "âšª No Pattern 3 detections for chunk chunk_53_20250605042635\n",
      "âœ… Marked chunk chunk_53_20250605042635 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_54_20250605042709\n",
      "âšª No Pattern 1 detections for chunk chunk_54_20250605042709\n",
      "âšª No Pattern 2 detections for chunk chunk_54_20250605042709\n",
      "âšª No Pattern 3 detections for chunk chunk_54_20250605042709\n",
      "âœ… Marked chunk chunk_54_20250605042709 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_55_20250605042744\n",
      "âšª No Pattern 1 detections for chunk chunk_55_20250605042744\n",
      "âšª No Pattern 2 detections for chunk chunk_55_20250605042744\n",
      "âšª No Pattern 3 detections for chunk chunk_55_20250605042744\n",
      "âœ… Marked chunk chunk_55_20250605042744 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_56_20250605042817\n",
      "âšª No Pattern 1 detections for chunk chunk_56_20250605042817\n",
      "âšª No Pattern 2 detections for chunk chunk_56_20250605042817\n",
      "âšª No Pattern 3 detections for chunk chunk_56_20250605042817\n",
      "âœ… Marked chunk chunk_56_20250605042817 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_57_20250605042851\n",
      "âšª No Pattern 1 detections for chunk chunk_57_20250605042851\n",
      "âšª No Pattern 2 detections for chunk chunk_57_20250605042851\n",
      "âšª No Pattern 3 detections for chunk chunk_57_20250605042851\n",
      "âœ… Marked chunk chunk_57_20250605042851 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_58_20250605042925\n",
      "âšª No Pattern 1 detections for chunk chunk_58_20250605042925\n",
      "âšª No Pattern 2 detections for chunk chunk_58_20250605042925\n",
      "âšª No Pattern 3 detections for chunk chunk_58_20250605042925\n",
      "âœ… Marked chunk chunk_58_20250605042925 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_59_20250605043002\n",
      "âšª No Pattern 1 detections for chunk chunk_59_20250605043002\n",
      "âšª No Pattern 2 detections for chunk chunk_59_20250605043002\n",
      "âœ… 1 DEI-NEEDED detections found in chunk chunk_59_20250605043002\n",
      "ğŸ’¾ Saved DEI-NEEDED batch 1 to s3a://banktransactionskrnl1/detections/test_detection_20250605_045944_60e1136b.csv\n",
      "âœ… Marked chunk chunk_59_20250605043002 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_5_20250605035904\n",
      "âšª No Pattern 1 detections for chunk chunk_5_20250605035904\n",
      "âšª No Pattern 2 detections for chunk chunk_5_20250605035904\n",
      "âšª No Pattern 3 detections for chunk chunk_5_20250605035904\n",
      "âœ… Marked chunk chunk_5_20250605035904 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_6_20250605035939\n",
      "âšª No Pattern 1 detections for chunk chunk_6_20250605035939\n",
      "âšª No Pattern 2 detections for chunk chunk_6_20250605035939\n",
      "âšª No Pattern 3 detections for chunk chunk_6_20250605035939\n",
      "âœ… Marked chunk chunk_6_20250605035939 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_7_20250605040015\n",
      "âšª No Pattern 1 detections for chunk chunk_7_20250605040015\n",
      "âšª No Pattern 2 detections for chunk chunk_7_20250605040015\n",
      "âšª No Pattern 3 detections for chunk chunk_7_20250605040015\n",
      "âœ… Marked chunk chunk_7_20250605040015 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_8_20250605040051\n",
      "âšª No Pattern 1 detections for chunk chunk_8_20250605040051\n",
      "âšª No Pattern 2 detections for chunk chunk_8_20250605040051\n",
      "âšª No Pattern 3 detections for chunk chunk_8_20250605040051\n",
      "âœ… Marked chunk chunk_8_20250605040051 as processed\n",
      "\n",
      "ğŸ“¦ Processing chunk: chunk_9_20250605040127\n",
      "âšª No Pattern 1 detections for chunk chunk_9_20250605040127\n",
      "âšª No Pattern 2 detections for chunk chunk_9_20250605040127\n",
      "âšª No Pattern 3 detections for chunk chunk_9_20250605040127\n",
      "âœ… Marked chunk chunk_9_20250605040127 as processed\n",
      "\n",
      "\n",
      "âœ… 15 minutes passed. Stopping Mechanism Y polling.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import boto3\n",
    "import re\n",
    "import psycopg2\n",
    "\n",
    "# AWS S3 setup\n",
    "s3 = boto3.client('s3')\n",
    "bucket = 'banktransactionskrnl1'\n",
    "prefix = 'chunks/'\n",
    "\n",
    "# Function to detect unprocessed chunks\n",
    "def detect_unprocessed_chunks():\n",
    "    result = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "    all_chunks = set()\n",
    "    for obj in result.get('Contents', []):\n",
    "        match = re.match(r'chunks/(.+?)/', obj['Key'])\n",
    "        if match:\n",
    "            all_chunks.add(match.group(1))\n",
    "    \n",
    "    # Fetch already-processed chunks from PostgreSQL\n",
    "    conn = psycopg2.connect(**PG_CONFIG)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT chunk_id FROM processed_chunks\")\n",
    "    processed = {row[0] for row in cur.fetchall()}\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "    return sorted(all_chunks - processed)\n",
    "\n",
    "# ğŸ” Polling loop with auto-exit after 5 minutes\n",
    "MAX_DURATION_SECONDS = 5 * 60  \n",
    "start_time = time.time()\n",
    "idle_counter = 0\n",
    "\n",
    "print(\"ğŸ”„ Starting Mechanism Y polling (5-minute session)...\")\n",
    "\n",
    "while time.time() - start_time < MAX_DURATION_SECONDS:\n",
    "    unprocessed_chunks = detect_unprocessed_chunks()\n",
    "\n",
    "    if unprocessed_chunks:\n",
    "        if idle_counter > 0:\n",
    "            print(f\"\\nğŸŸ¢ New chunks found after {idle_counter} idle checks!\")\n",
    "            idle_counter = 0\n",
    "        for chunk_id in unprocessed_chunks:\n",
    "            process_chunk(chunk_id)\n",
    "    else:\n",
    "        if idle_counter == 0:\n",
    "            print(\"â³ Waiting for new chunks\", end=\"\", flush=True)\n",
    "        else:\n",
    "            print(\".\", end=\"\", flush=True)\n",
    "        idle_counter += 1\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"\\nâœ… 5 minutes passed. Stopping Mechanism Y polling.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60b62b29-d4a7-4941-b5fc-7378c4dad450",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Logs in Postgres within Databricks itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59b6b98c-ce42-40cb-9416-850a160dab49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+--------------------------+\n",
      "|chunk_id               |processed_at              |\n",
      "+-----------------------+--------------------------+\n",
      "|chunk_9_20250605040127 |2025-06-05 05:01:33.271735|\n",
      "|chunk_8_20250605040051 |2025-06-05 05:01:16.478478|\n",
      "|chunk_7_20250605040015 |2025-06-05 05:00:58.260752|\n",
      "|chunk_6_20250605035939 |2025-06-05 05:00:41.630211|\n",
      "|chunk_5_20250605035904 |2025-06-05 05:00:20.175719|\n",
      "|chunk_59_20250605043002|2025-06-05 04:59:53.54403 |\n",
      "|chunk_58_20250605042925|2025-06-05 04:59:25.364176|\n",
      "|chunk_57_20250605042851|2025-06-05 04:59:08.071549|\n",
      "|chunk_56_20250605042817|2025-06-05 04:58:50.877979|\n",
      "|chunk_55_20250605042744|2025-06-05 04:58:27.70714 |\n",
      "+-----------------------+--------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rds_url = \"jdbc:postgresql://bankdb-1.cvw2g6mimvrd.ap-south-1.rds.amazonaws.com:5432/bankdata\"\n",
    "rds_properties = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"Bappa143\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "# Read from RDS table\n",
    "processed_df = spark.read.jdbc(\n",
    "    url=rds_url,\n",
    "    table=\"processed_chunks\",\n",
    "    properties=rds_properties\n",
    ")\n",
    "\n",
    "# Show latest 10 entries\n",
    "processed_df.orderBy(\"processed_at\", ascending=False).show(10, truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Mechanism_Y_PollAndProcess",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
